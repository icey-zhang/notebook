
**面向数字基础设施**的开源操作系统（openEuler）

开放原子开放基金会

基于linux的开源操作系统

服务器、云计算、边缘计算、嵌入式等多个应用场景

并且支持多种主流芯片

社区发行版：有欧拉社区维护构建，完全免费 LTS长期支持版本

商业发行版：硬件厂商


嵌入式用来实现**某种特定功能**的计算机系统

硬件：处理器、存储器

软件：底层驱动、**操作系统**


SIG组合 特殊兴趣小组 special inteste grop

维护者 提交者 贡献者

2.1 为什么需要 OS for AI
在现阶段大家的认知中，大模型是非常依赖高算力资源的，并且其对算力的需求增长（上方图的红色的线）也是非常快速。而算力的增长（上方图的蓝色线）速度却远远跟不上算力需求的增长。那么如何才能将两条线之间的差距减少呢？这其中一种方法是提高蓝线，也就是增加算力，但是从下图总结也可以看出，大模型每年增长10倍的时候，GPU的算力才能增加1倍，这显然是无法达到或者说现阶段GPU算力是无法赶上模型的算力需求的。这条路显然是不通的；另外一个我们可控的方法是对软件进行优化，这不仅仅是针对一方面进行优化，接下来我们会详细说明操作系统 OS 在 AI 业务生命周期内如何进行优化的。
![image](https://github.com/icey-zhang/notebook/assets/54712081/4284b09b-be95-429a-ab65-8ce9c93e54e8)


2.2 OS for AI 的优化
![image](https://github.com/icey-zhang/notebook/assets/54712081/35ead898-e788-4135-bcd2-f3a0b116787c)


还记得最开始 ChatGPT 发布的时候，Google 的 AI 模型也在发布，他们的时间可以说互相角逐非常紧密，都希望能够比竞品更早的发布以及打入和落地市场。在 AI 的整个生命周期中，开发阶段是最开始的，在开发阶段，操作系统希望能够帮助团队进行快速的开发、测试以及发布。操作系统的标准化，操作系统的稳定性，以及性能与软件识别上，这些都会影响开发、测试甚至发布的效率。

而在训练阶段，操作系统帮助做的是故障检测、隔离以及恢复。训练模型是一个非常耗时耗力的过程，而且往往其量级都是非常庞大的，在这个过程中，如果出现某一故障，一般就会造成一些大家不想期望的中断以及效率的下降。比如说如果某一个程序或者训练模型出现错误，虽然程序可能有自己的自检测功能，但是就和上面讲过的，这期间可能会剥离一部分算力去自检这个异常，这样就间接的造成了算力的下降。而更加可怕的是，如果出现了雪崩效应，其中一个节点出现算力下降或者中断，很有可能会造成整个训练过程的效率下降甚至是训练中断。

在部署/运维阶段，操作系统所提供的的帮助主要关注点依然是增加效率，这包括如何进行快速部署，环境的预优化并且进行指标监控。再这一点上，我们后面会拿华为云的 EulerCopilot 举例来说。

而在最终业务应用推理阶段，操作系统所提供的的帮助是进行任务加速与调度，并且提升利用率。

可以说在 AI 的生命周期中，操作系统 OS 扮演关键角色。在开发阶段，标准化和性能直接影响效率；训练阶段则需故障检测，防止效率降低；部署阶段专注于快速部署和监控；最终业务应用推理阶段注重任务加速与调度。操作系统的作用贯穿始终，对于实现高效的AI开发、训练和部署至关重要。

2.2.1 OS for AI 开发场景的优化
在开发阶段通常面临的挑战：快速开发、快速测试、快速发布
![image](https://github.com/icey-zhang/notebook/assets/54712081/4b60b472-af45-4fe5-b2dc-76ef1c48dedf)

操作系统（OS）在开发阶段是如何进行优化的呢？或许你会产生这样的疑问。之前我已经提到了重庆小面的案例，再拿出来说明一下，你就会更直观地了解操作系统在AI开发阶段优化的重要性。 如果你是一个厨师，正打算做一碗重庆小面，常规的做法是，需要先准备好面条，调料，当然这也可能有辣椒、麻酱、各种调料等等，之后加热锅，在开始煮面。但是你有没有想过，如果你作为一位厨师，当顾客要一碗重庆小面的时候，你进入到厨房，这些调料以及食材已经全部准备好了，你所关心的只是下面开始做小面即可。而把这个场景带入到操作系统 OS 优化开发场景中，你会发现，在 AI 的开发过程中，操作系统可以预置好相关的镜像、管理相关的模型，甚至进行预置训练框架，这样我们就可以给客户提供一个一体化方案，这样客户可以快速搭建一个 AI 开发基础平台从而快速的开展开发业务。


2.2.2 OS for AI 训练场景的优化

在训练阶段通常面临的挑战：保障长时间、大集群的训练任务稳定执行，不被中断。
![image](https://github.com/icey-zhang/notebook/assets/54712081/88bdcccf-0b7d-4241-b3ad-35b54d3b543a)

操作系统 OS 在 AI 训练场景的优化主要有这几个方面：可观测能力、故障预测、故障隔离以及故障自愈。

可观测能力方面，操作系统可以认为在应用与硬件中起着承上启下的重要作用，操作系统既连接了硬件资源，又连接了软件资源，这样操作系统可以多方面的进行收集监控信息，这比如：硬件信息、网络信息、内核信息、容器、应用信息与日志信息等，从而我们可以从多个维度与角度去收集观察相关信息；我们有了上述的众多维度的信息后，我们就可以对故障进行预测。基于观测数据，从而预测硬件、集群甚至是业务的故障，另一方面我们也可以使用 AI 模型来提高预测能力以及预测精准度；上面我们有说道我们所收集的数据是全方位的，包括软硬件的信息，这样在发生故障的时候，我们进而可以精准的定位甚至预测故障，与此同时，这样的操作系统还可以对故障进行隔离，在集群中自动隔离故障节点，而在节点中利用软件协同自动隔离故障部件；而我们最终的目标/方向是进行故障自愈，比如内存故障自愈，故障的组件自动重置亦或故障系统快速重部署等。


2.2.3 OS for AI 部署、运维优化
在部署、运维阶段通常面临的挑战：快速完成 AI 基础设施环境的安装与部署，并通过基本验证。
![image](https://github.com/icey-zhang/notebook/assets/54712081/85e90912-138b-45e1-9df9-bca8f15988d8)

在说一堆术语之前，我们这里还拿重庆小面做举例，还是之前的场景，你是一位厨师，在准备做重庆小面的时候，发现居然还要生火烧水，而烧开水这是一个漫长的等待过程，也许顾客会要2两小面、或者三两小面，你如何来进行称重，而其他的方面你也许需要准备调料的多少也是一个挑战。而这些挑战如果发生是在 AI 程序部署阶段，那么一般的团队会是非常头疼，因为一般厂商或者团队，面临软硬件相关的作业可能不是单纯的一个团队能够完全完成的，这可能涉及到多个团队来协作数周的时间才能完成，而在这个过程中，如果操作系统 OS 已经预置了这些，那么将会大大的减少时间与成本，从而增加效率。


2.2.4 OS for AI 推理场景优化
在推理场景通常面临的挑战：推理设施利用率低
![image](https://github.com/icey-zhang/notebook/assets/54712081/0b81d217-55d8-41a4-817f-2e51e6c694a1)

AI推理场景中，优化的重点是提高模型的推理速度和准确率，以及减少资源消耗。推理场景的优化中主要有两个方面，一方面是各大基础设施硬件的厂商，主要关注在大模型在运行时，如何提高硬件的运行效率以及利用率在推理过程中，可以从模型优化、系统优化、数据优化等方面入手。另一个方面是系统优化包括系统资源管理、内存优化、多线程、推理框架、部署方式等方面，可以提高推理速度。数据优化包括数据预处理、数据增强、数据缓存等方面，可以提高推理速度。部署方式优化包括部署方式选择、部署平台选择、部署方案选择等方面，可以提高推理速度。其他方面包括模型训练、数据集选择、硬件选择、硬件配置、迁移学习、模型融合等，可以提高推理准确率。


三、展望 AI for OS
![image](https://github.com/icey-zhang/notebook/assets/54712081/4b2271c9-2abf-4d08-a9ce-c6b3cbae9882)

接下来我们探讨一下 AI 在操作系统 OS 中有那些应用场景和挑战。其实毫不严重的说，我个人感觉只要你能想到的场景，AI 都可能会介入，如果在操作系统场景下，那么我们之前已经提到的还有没提到的方面 AI 都可能有应用的机会，比如：

自动优化
自动运维
故障分析预测
安全扫描分析
自我防护
Copilot
虽然 AI 的应用场景角度非常之多，但是也同样面临着一些挑战，比如我们很多的 AI 产品都是基于 Python 开发，并且依赖的外部组件较多，这样其 AI 产品体积就比较大，结合这几点你会发现这些都与现阶段的操作系统相悖，一般而言，操作系统都是体量较小，占有资源不多，这样才会分配更多的资源给上层的应用，所以如果展望未来，想要将 AI 纳入操作系统级别的基础服务的话，我们需要一个体积小、依赖少、安全可靠并且高性能的 AI 框架。

四、欧拉与 AI 的深度结合：EulerCopilot
我们在文章中重点介绍了操作系统于 AI 的相爱相生的关系，大型模型使操作系统更加智能。欧拉作为首个广泛支持人工智能的开源操作系统，正在颠覆传统的命令行交互方式。华为采用ChatGLM基础模型，结合大量欧拉操作系统的代码和数据进行训练，成功开发出EulerCopilot。该系统初步实现了代码辅助生成、问题智能分析和系统辅助运维等功能。以往需要多领域专家协同解决的问题，如今都可以交由 EulerCopilot 轻松处理。
4.1 什么是 EulerCopilot
以下是个人总结的一个关于 EulerCopilot 的介绍：

EulerCopilot 是一款操作系统基础服务级别的智能 AI 产品，其 AI能力与欧拉系统相结合打造出新一代的智能化操作系统。这一系统初步实现了代码生成辅助、智能问题分析以及系统运维等功能，使得 openEuler 在智能化方面取得显著进展。

EulerCopilot的官方文档信息点击这里

4.2 EulerCopilot 应用示例
1. Web端智能问答平台，快速获取领域知识

EulerCopilot 可以是一款智能问答平台，我们可以从中快速获取领域知识。其功能包括知识收集，整合了openEuler 专业书籍、20+ 上游社区知识、社区论坛/博客、案例积累、业内新闻以及开源社区官方代码仓等。在模型训练方面，使用领域知识对大型模型进行微调，结合向量数据库，以提供用户更优质的使用体验。通过RLAIF和RLHF方法，收集人工智能和人类用户对模型输出的反馈，以进一步优化模型和语料库。
![image](https://github.com/icey-zhang/notebook/assets/54712081/8deff22d-2322-4821-8b06-e192d6caf957)

2. 强大的智能 Shell

如果你是运维人员想必一定不会陌生 Shell，但是如果你是新手小白，或者根本不懂Shell，那么操作Linux命令将非常麻烦，如果有了EulerCopilot 你就可以使用自然语言来操作 Linux中的 Shell了。

用户使用自然语言对 EulerCopilot 提出要求：
![image](https://github.com/icey-zhang/notebook/assets/54712081/b3bcf701-972f-40fb-b724-a4743cbd954a)

而在终端中 EulerCopilot 直接会回复：
mkdir test && cp /root/*.json test/ && tar -czvf test.tar.gz test/
EulerCopilot: 是否执行以上密令？[y/n]

![image](https://github.com/icey-zhang/notebook/assets/54712081/77b1ee4c-0a2e-4b77-a948-bcb6df66f37d)

我们在是否执行询问中，回答 y 后，命令被自动执行。

![image](https://github.com/icey-zhang/notebook/assets/54712081/1ef94e5e-bb51-4140-8b81-2030d68d9147)

之后我们执行查询命令后，可以看到直接打包的文件。
ls /root | grep test

![image](https://github.com/icey-zhang/notebook/assets/54712081/39e7a7a9-1f23-4a01-afe3-c90ee749c541)

五、文末总结
通过本文章解析了人工智能（AI）和操作系统（OS）之间的密切合作，可以更加加深它们在大模型时代下的关系与重要性。我们通过讲述重庆小面的故事引入，生动形象地说明了 AI 如何像厨师助手一样，在各个阶段帮助我们更高效地工作。文章详细介绍了操作系统在AI开发、训练、部署和推理阶段的优化方法，强调了其在整个 AI 生命周期中的关键作用。最后，通过华为的 EulerCopilot 案例，展望了未来AI 在操作系统中的广泛应用，为智能化操作系统带来了新的可能性。希望本篇文章能够对操作系统以及 AI 领域的小伙伴有所帮助

参考：[操作系统与 AI 大模型时代下的默契合作与未来展望](https://bbs.huaweicloud.com/blogs/420527?ticket=ST-82276879-uS0v7zAHaAIQgmFDK4Yf4MfA-sso)
