# Adding Conditional Control to Text-to-Image Diffusion Models


<img width="545" alt="image" src="https://github.com/icey-zhang/notebook/assets/54712081/90b4ccc6-63a1-4e68-b7ef-fb7c24e7a3d8">

[【Paper】](https://arxiv.org/pdf/2302.05543) [【Code】](https://github.com/lllyasviel/ControlNet)

**通义千问生成**

## 全文摘要
本文介绍了一种名为ControlNet的神经网络架构，可以将条件控制添加到大型预训练文本到图像扩散模型中。该方法利用了预训练模型的强大编码层作为强大后背，并使用“零卷积”技术逐渐增加参数，确保不会对微调产生负面影响。作者在Stable Diffusion上测试了各种条件控制，如边缘、深度、分割和人类姿势等，结果表明ControlNet可以在小（少于50K）和大（超过1M）数据集上进行稳健训练。实验结果表明，ControlNet可以使更广泛的应用来控制图像扩散模型。

![image](https://github.com/icey-zhang/notebook/assets/54712081/ec487e5d-d014-434f-b4f3-206f4020a2da)


## 论文速读
### 论文方法
#### 方法描述
该论文提出了一种名为ControlNet的神经网络架构，可以增强大型预训练图像到文本扩散模型的空间局部化、任务特定的图像条件。ControlNet将额外的条件注入到神经网络块中，并且通过锁定原始块的参数并同时克隆一个可训练的副本来实现。该可训练副本接收外部条件向量作为输入，并利用大型预训练模型建立强大的后背以处理各种输入条件。此外，该论文还介绍了如何将ControlNet应用于图像扩散模型Stable Diffusion，以及在训练和推断过程中需要注意的一些问题。

#### 方法改进
与传统的扩散模型相比，ControlNet能够提供更灵活和精细的控制，因为它允许用户为每个神经网络块添加不同的条件。此外，该论文提出的Gradient Calculation for Zero Convolution也使得有害噪声不会影响神经网络层的状态，从而提高了模型的稳定性和可靠性。

#### 解决的问题
该论文主要解决了如何提高图像扩散模型的灵活性和可控性的问题。通过使用ControlNet，用户可以根据需要为每个神经网络块添加不同的条件，从而更好地控制生成的图像。此外，通过使用Zero Convolution保护后背，该方法还可以消除随机噪声，提高模型的稳定性和可靠性。


### 论文实验
本文主要介绍了作者使用ControlNets结合Stable Diffusion进行图像生成的实验，并进行了多种条件下的测试和比较。具体来说，作者进行了以下四个方面的实验：

实验内容：作者首先介绍了他们实现ControlNets的方法以及所使用的各种条件，包括Canny Edge、Depth Map、Normal Map、M-LSD线条、HED软边缘、ADE20K分割、Openpose和用户草图等。此外，作者还在补充材料中提供了每种条件的具体例子以及详细的训练和推理参数。

质量评估：作者展示了不同提示设置下生成的图像，并在没有提示、提示不足、提示冲突和完美提示四种情况下进行了评估。结果表明，ControlNet能够成功地解释各种输入条件中的语义信息。

模型结构研究：作者通过两种方式对ControlNets进行了替代结构的研究：一是用标准卷积层替换零卷积层，二是将每个块的可训练副本替换为一个单个卷积层，称为ControlNet-lite。作者还提出了四种可能的行为场景来测试这些模型，结果表明，当零卷积被替换时，ControlNet的表现会下降到与ControlNet-lite相当的程度，这表明预训练的可训练副本在微调过程中被破坏了。

量化评估：作者采用了用户调查、与其他工业模型的比较、条件重建和FID分数等多种方法来进行量化评估。其中，用户调查是通过对20张手绘草图进行排名的方式来衡量结果质量和条件保真度的。与其他工业模型的比较则是通过让12名用户区分由SDV2-D2I和ControlNet生成的200张图像来完成的。最后，作者还使用不同的分割条件方法生成图像，并计算OneFormer的重建成本，同时使用FID分数、CLIP分数和CLIP美学分数来衡量分布距离和美学质量等方面的差异。

总的来说，本文的实验结果表明，ControlNets结合Stable Diffusion可以有效地处理多样化的条件，并产生清晰、锐利的结果。此外，作者还提出了一些替代结构和量化评估方法，以进一步提高模型的性能和可靠性。

## 论文总结
### 文章优点
该论文提出了一种名为ControlNet的神经网络结构，用于学习控制大型预训练文本到图像扩散模型的条件控制。通过保留大型模型的质量和能力，并锁定其参数，同时创建一个可训练的编码层副本来实现这一目标。这种方法可以有效地控制稳定扩散，包括使用各种条件输入，如边缘地图、人体姿态骨架、分割映射等。此外，该方法还具有稳健性和可扩展性，可以在不同大小的数据集上进行训练，并且在某些任务中可以获得与工业级模型相当的结果。

### 方法创新点
该论文的主要贡献是提出了一种新的神经网络结构，即ControlNet，它可以通过连接一个可训练的编码层副本和一个锁定的大规模预训练模型来实现条件控制。这种结构保护了大规模预训练模型的质量和能力，并确保不会添加有害噪声到深度特征中。此外，该方法还可以处理复杂的形状和多样化的高阶语义，使其适用于更广泛的条件控制问题。

### 未来展望
该论文提出的方法为解决文本到图像扩散模型中的条件控制问题提供了一个有效的方法。未来的研究方向可能包括进一步优化ControlNet的架构以提高性能，探索如何将此方法应用于其他类型的扩散模型以及将其与其他技术（例如GAN）结合使用以获得更好的结果。此外，该方法还可以应用于其他计算机视觉领域的问题，例如图像翻译和图像编辑。
