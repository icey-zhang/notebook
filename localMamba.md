# 介绍
Mamba 模型利用选择性 SSM，不仅实现了序列长度的线性可扩展性，而且在语言建模任务中提供了具有竞争力的性能。这种成功启发了后续视觉任务的应用，并提出了将 Mamba 集成到基础视觉模型的研究。**Vim[60]**采用类似**vit的体系结构**，**结合双向Mamba块代替传统的变压器块**。**Vamba[32]**引入了一种新的**2D选择性扫描技术来扫描水平和垂直方向的图像**，并构建了一个类似于**Swin Transformer[33]**的分层模型。我们的研究扩展了这些最初的探索，专注于优化视觉任务的 S6 适应，我们实现了改进的性能结果。

| 模型 | 类似于 | 特点 |
|-------|-------|-------|
| Vim | vit | 结合双向Mamba块代替传统的变压器块 |
| Vamba | Swin Transformer | 2D选择性扫描技术来扫描水平和垂直方向的图像 |

# 方法
本节描述 LocalMamba 的核心组件，从旨在增强模型从图像中挖掘细粒度细节的能力的局部扫描机制开始。随后，我们介绍了扫描方向搜索算法，这是一种创新的方法，可以识别不同层的最佳扫描序列，从而确保了全局和局部视觉线索的和谐集成。本节的最后一部分说明了 LocalMamba 框架在简单的普通架构和复杂的层次结构中的部署，展示了它在不同设置中的通用性和有效性。

## 视觉表示的局部扫描
我们的方法采用选择性扫描机制 S6，在处理一维因果序列数据方面表现出卓越的性能。该机制对输入进行因果处理，有效地捕获扫描段内的重要信息，类似于理解顺序单词之间依赖关系的语言建模。**然而，图像中二维空间数据固有的非因果性质对这种因果处理方法提出了重大挑战。**传统的扁平化空间令牌的策略损害了局部2D依赖关系的完整性，从而降低了模型有效识别空间关系的能力。例如，如图 1 (a) 和 (b) 所示，Vim [60] 中使用的扁平化方法破坏了这些局部依赖关系，显着提高了垂直相邻标记之间的距离，并阻碍了模型捕获局部细微差别的能力。虽然VMamba[32]试图通过在水平和垂直方向上扫描图像来解决这个问题，但它仍然无法在单个扫描中全面处理空间区域。

<img width="451" alt="image" src="https://github.com/icey-zhang/notebook/assets/54712081/dd32022a-50fd-4080-b42e-4be0d8a4b155">
